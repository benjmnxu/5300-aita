{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "csv_path = \"data/train.csv\"  \n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "nta_data = data[data['target'] == 'NTA']\n",
    "other_data = data[data['target'] != 'NTA']\n",
    "\n",
    "nta_sample = resample(nta_data, n_samples=3000, random_state=42)\n",
    "other_sample = resample(other_data, n_samples=3000, random_state=42)\n",
    "\n",
    "balanced_data = pd.concat([nta_sample, other_sample])\n",
    "\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_data.to_csv(\"data/balanced_train_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "csv_path = \"data/dev.csv\"  \n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "nta_data = data[data['target'] == 'NTA']\n",
    "other_data = data[data['target'] != 'NTA']\n",
    "\n",
    "nta_sample = resample(nta_data, n_samples=375, random_state=42)\n",
    "other_sample = resample(other_data, n_samples=375, random_state=42)\n",
    "\n",
    "balanced_data = pd.concat([nta_sample, other_sample])\n",
    "\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_data.to_csv(\"data/balanced_dev_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "csv_path = \"data/test.csv\"  \n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "nta_data = data[data['target'] == 'NTA']\n",
    "other_data = data[data['target'] != 'NTA']\n",
    "\n",
    "nta_sample = resample(nta_data, n_samples=375, random_state=42)\n",
    "other_sample = resample(other_data, n_samples=375, random_state=42)\n",
    "\n",
    "balanced_data = pd.concat([nta_sample, other_sample])\n",
    "\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_data.to_csv(\"data/balanced_test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/rhmcv55s2sx0f17r7cqcf04h0000gn/T/ipykernel_68973/635985684.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['pred_verdict'] = test_data['body'].apply(pred_verdict)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"data/dev.csv\" \n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "test_data = data[0:1500] # insert assigned chunk here \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"here\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def pred_verdict(text):\n",
    "    try:\n",
    "        # columns = [\n",
    "        #     \"body\", \"num_comments\", \"score\", \"upvote_ratio\",\n",
    "        #     \"title\", \"id\", \"length_body\"\n",
    "        # ]\n",
    "\n",
    "        # # Creating a readable text format for each column\n",
    "        # text_parts = [\n",
    "        #     f\"The {col.replace('_', ' ')} is: {{test_data['{col}']}}\"\n",
    "        #     for col in columns\n",
    "        # ]\n",
    "\n",
    "        # # Joining all parts into a single string\n",
    "        # final_text = \". \".join(text_parts) + \".\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful agent.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"You are a classifier for posts in the Am I the Asshole subreddit. Your task is to classify each post into one of the following categories: \\\"NTA\\\" (Not the Asshole), \\\"YTA\\\" (You're the Asshole), \\\"ESH\\\" (Everyone's the Asshole), and \\\"NAH\\\" (No Assholes Here), primarily based on the interpersonal behavior the user describes in the body text. Provide only the category name as the output. :\\n{text}. Category: \"}\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        return None\n",
    "\n",
    "test_data['pred_verdict'] = test_data['body'].apply(pred_verdict)\n",
    "\n",
    "test_data.to_csv(\"data/dev_predicted_100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NTA\n",
      "1    YTA\n",
      "2    NTA\n",
      "3    NTA\n",
      "4    NTA\n",
      "5    YTA\n",
      "6    NTA\n",
      "7    NTA\n",
      "8    NAH\n",
      "9    ESH\n",
      "Name: pred_verdict, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_data['pred_verdict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NTA\n",
      "1    YTA\n",
      "2    NTA\n",
      "3    NTA\n",
      "4    NTA\n",
      "5    YTA\n",
      "6    NTA\n",
      "7    NTA\n",
      "8    NTA\n",
      "9    NTA\n",
      "Name: target, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data/dev_predicted_100.csv\" \n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "with open(\"labels/dev_100_pred.txt\", \"w\") as pred_file:\n",
    "    for pred in data['pred_verdict']:\n",
    "        pred_file.write(f\"{pred}\\n\")\n",
    "\n",
    "with open(\"labels/dev_100_true.txt\", \"w\") as true_file:\n",
    "    for true_label in data['target']:\n",
    "        true_file.write(f\"{true_label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
